{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# @Time : 2021/4/19 13:44\n",
    "# @Author : Jclian91\n",
    "# @File : torch_loss_function_test.ipynb\n",
    "# @Place : Yangpu, Shanghai\n",
    "import math\n",
    "import torch as T\n",
    "from sklearn.metrics import log_loss\n",
    "from torch.nn import MSELoss, L1Loss, BCELoss, CrossEntropyLoss, NLLLoss, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of Mean Squared Error is 2.5\n"
     ]
    }
   ],
   "source": [
    "# mse\n",
    "y_true = T.tensor([[10.0], [7.0]])\n",
    "y_pred = T.tensor([[8.0], [6.0]])\n",
    "loss = MSELoss()(y_pred, y_true)\n",
    "print(f'Value of Mean Squared Error is {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of Mean Absolute Error is 1.5\n"
     ]
    }
   ],
   "source": [
    "# mae\n",
    "y_true = T.tensor([[10.0, 7.0]])\n",
    "y_pred = T.tensor([[8.0, 6.0]])\n",
    "loss = L1Loss()(y_pred, y_true,)\n",
    "print(f'Value of Mean Absolute Error is {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Binary Cross Entropy in python: 0.164252033486018\n",
      "Compute Binary Cross Entropy in Torch: 0.16425204277038574\n"
     ]
    }
   ],
   "source": [
    "# Binary Cross Entropy\n",
    "y_true = T.tensor([[1.0], [0.0]])\n",
    "y_pred = T.tensor([[0.9], [0.2]])\n",
    "loss = BCELoss()(y_pred, y_true)\n",
    "python_loss = (1.0 * (-math.log(0.9)) + 1.0 * (-math.log(0.8)))/2\n",
    "print(f'Compute Binary Cross Entropy in python: {python_loss}')\n",
    "print(f'Compute Binary Cross Entropy in Torch: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred in softmax:  tensor([[0.1332, 0.2038, 0.6631],\n",
      "        [0.1106, 0.1886, 0.7008],\n",
      "        [0.3300, 0.4201, 0.2499]])\n",
      "compute CCE by python: 1.6903224324257253\n",
      "compute CCE by sklearn: 1.6903224388758342\n",
      "compute CCE by Torch CrossEntropyLoss: 1.6903223991394043\n",
      "compute CCE by Torch Operation: 1.6903223991394043\n",
      "compute CCE by validation: 1.6903223991394043\n"
     ]
    }
   ],
   "source": [
    "# Categorical Cross Entropy\n",
    "y_true = [[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]\n",
    "y_true_torch = T.tensor([0, 1, 2])\n",
    "y_pred_tmp = T.randn(3, 3)\n",
    "y_pred = Softmax(dim=1)(y_pred_tmp)\n",
    "print(\"y_pred in softmax: \", y_pred)\n",
    "y_pred_numpy = y_pred.numpy()\n",
    "loss = (-math.log(y_pred_numpy[0][0])-math.log(y_pred_numpy[1][1])-math.log(y_pred_numpy[2][2]))/3\n",
    "print(f\"compute CCE by python: {loss}\")\n",
    "loss = log_loss(y_true, y_pred)\n",
    "print(f\"compute CCE by sklearn: {loss}\")\n",
    "loss = CrossEntropyLoss()(y_pred_tmp, y_true_torch)\n",
    "print(f\"compute CCE by Torch CrossEntropyLoss: {loss}\")\n",
    "log_value = T.log(y_pred)\n",
    "torch_loss = T.sum(T.tensor(y_true).mul(-log_value))/3\n",
    "print(f\"compute CCE by Torch Operation: {torch_loss}\")\n",
    "torch_cce_loss = NLLLoss()(log_value, y_true_torch)\n",
    "print(f\"compute CCE by validation: {torch_cce_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hinge loss:  tensor(0.6500)\n"
     ]
    }
   ],
   "source": [
    "# hinge loss\n",
    "class MyHingeLoss(T.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyHingeLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        # output和target都是1-D张量,换句话说,每个样例的返回是一个标量.\n",
    "        hinge_loss = 1 - T.sum(T.mul(output, target), dim=0)\n",
    "        hinge_loss[hinge_loss < 0] = 0\n",
    "        return T.mean(hinge_loss)\n",
    "\n",
    "\n",
    "y_true = T.tensor([[0., 1.], [1., 0.]])\n",
    "y_pred = T.tensor([[0.7, 0.3], [0.4, 0.6]])\n",
    "loss = MyHingeLoss()(y_pred, y_true)\n",
    "print(\"hinge loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
